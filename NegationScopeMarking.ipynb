{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653e757-1d09-4114-a393-8ede30bafadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# the CSV should have columns: 'id', 'label', 'tweet'\n",
    "df = pd.read_csv(\"/Users/neilkadian/Downloads/Default Safari Downloads Folder/sentiment_analysis.csv\")\n",
    "\n",
    "# verify the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# define common negation words\n",
    "NEGATION_WORDS = [\"not\", \"never\", \"no\", \"none\", \"n't\", \"cannot\", \"neither\", \"nor\"]\n",
    "\n",
    "def mark_negation_scope(text):\n",
    "    \"\"\"Mark negation scope in text.\"\"\"\n",
    "    words = text.split()\n",
    "    negated = False\n",
    "    marked_text = []\n",
    "\n",
    "    for word in words:\n",
    "        # chheck for negation word match\n",
    "        if any(re.search(rf'\\b{neg_word}\\b' if neg_word != \"n't\" else r\"\\b\\w*n't\\b\", word.lower()) for neg_word in NEGATION_WORDS):\n",
    "            negated = True\n",
    "            marked_text.append(\"NEG_\" + word)\n",
    "        elif negated and re.match(r'[,.!?]', word):  # End negation scope at punctuation\n",
    "            negated = False\n",
    "            marked_text.append(word)\n",
    "        elif negated:\n",
    "            marked_text.append(\"NEG_\" + word)\n",
    "        else:\n",
    "            marked_text.append(word)\n",
    "    \n",
    "    return \" \".join(marked_text)\n",
    "\n",
    "# apply negation scope marking\n",
    "df['marked_tweet'] = df['tweet'].apply(mark_negation_scope)\n",
    "\n",
    "# ssample the full dataset\n",
    "sample_fraction = 1\n",
    "df_sampled = df.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_sampled[\"marked_tweet\"], df_sampled[\"label\"], test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Size of train_texts: {len(train_texts)}\")\n",
    "print(f\"Size of test_texts: {len(test_texts)}\")\n",
    "\n",
    "# load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# add NEG_ token to vocabulary\n",
    "tokenizer.add_tokens([\"NEG_\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# tokenize the data\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)\n",
    "\n",
    "# convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"labels\": list(train_labels)\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"labels\": list(test_labels)\n",
    "})\n",
    "\n",
    "# load DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d88a9-5a93-4606-aa70-b471f4d6d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# check if MPS is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# move the model to the MPS device\n",
    "model = model.to(device)\n",
    "\n",
    "# function to test the model on multiple inputs\n",
    "def test_model_on_multiple_inputs(input_texts, model, tokenizer, device):\n",
    "    predicted_sentiments = []  # List to store predictions for each input\n",
    "    sentiment_map = {1: \"Negative\", 0: \"Positive\"}  # Sentiment mapping\n",
    "    \n",
    "    for input_text in input_texts:\n",
    "        # tokenize the input\n",
    "        encoding = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        \n",
    "        # Move the tokenized input to the correct device\n",
    "        encoding = {key: value.to(device) for key, value in encoding.items()}\n",
    "        \n",
    "        # pass the tokenized input through the model\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            outputs = model(**encoding)\n",
    "        \n",
    "        # geet the predicted label\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "        \n",
    "        # map the predicted label to sentiment and add it to the list\n",
    "        predicted_sentiments.append(sentiment_map[predicted_label])\n",
    "    \n",
    "    return predicted_sentiments\n",
    "\n",
    "input_texts = [\n",
    "    \"#OnePlusOne is beast of a phone, finally bought one & now just can't get my hands off it. #enjoyingmyself #thankyou #Oneplus #inlove\",\n",
    "    \"I don't think I've ever loved my iPhone more than with the new iOS5 update!! #apple #appleiosupdate\",\n",
    "    \"I have to give some to #apple for the #Iphone . I dropped my #iphone in the sink today and not one problem. Thank you #Apple !\",\n",
    "    \"@JamesDawute I like tablets but personally I have no use for it So in that sense Im not a fan but I think its quite a gd product\",\n",
    "    \"I just can't do it. Every time I look at a PC laptop, it only makes me want a MacBook Pro even more... Apple\",\n",
    "    \"Now my girl will never pay any attention to me now she just got an iPhone 5\"\n",
    "]\n",
    "\n",
    "predicted_sentiments = test_model_on_multiple_inputs(input_texts, model, tokenizer, device)\n",
    "\n",
    "# print results for each input\n",
    "for input_text, sentiment in zip(input_texts, predicted_sentiments):\n",
    "    print(f\"Input Text: {input_text}\")\n",
    "    print(f\"Predicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2779a29-4f92-49d0-8ed8-b7e37eb09095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_negation(text):\n",
    "    \"\"\"Check if a text contains any negation words.\"\"\"\n",
    "    text = text.lower()\n",
    "    return any(re.search(rf'\\b{neg_word}\\b' if neg_word != \"n't\" else rf\"{neg_word}\\b\", text) for neg_word in NEGATION_WORDS)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the categories for analysis\n",
    "categories = [\n",
    "    \"Negative Label, Not Negated\",\n",
    "    \"Negative Label, Negated\",\n",
    "    \"Positive Label, Not Negated\",\n",
    "    \"Positive Label, Negated\",\n",
    "]\n",
    "\n",
    "# predict on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# process test data into input text and true labels\n",
    "test_texts = test_texts.reset_index(drop=True)  # Ensure proper indexing\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Initialize the matrix\n",
    "matrix = np.zeros((4, 2), dtype=int)\n",
    "\n",
    "# fill the matrix\n",
    "for i, text in enumerate(test_texts):\n",
    "    true_label = test_labels[i]\n",
    "    predicted_label = predicted_labels[i]\n",
    "    negation_flag = contains_negation(text)  # Use the negation function defined earlier ######\n",
    "\n",
    "    # Determine the row index based on true label and negation status\n",
    "    if true_label == 1:  # Negative sentiment\n",
    "        row = 0 if not negation_flag else 1\n",
    "    elif true_label == 0:  # Positive sentiment\n",
    "        row = 2 if not negation_flag else 3\n",
    "\n",
    "    # determine the column index based on predicted label\n",
    "    col = 0 if predicted_label == 1 else 1\n",
    "\n",
    "    # Update the matrix\n",
    "    matrix[row, col] += 1\n",
    "\n",
    "# calculate total number of test samples\n",
    "total_test_samples = len(test_texts)\n",
    "\n",
    "# calculate percentages\n",
    "percent_matrix = (matrix / total_test_samples) * 100\n",
    "\n",
    "# visualize the matrix\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# calculate total negated and non-negated inputs\n",
    "negated_rows = [1, 3]  # Rows corresponding to negated inputs\n",
    "non_negated_rows = [0, 2]  # Rows corresponding to non-negated inputs\n",
    "\n",
    "# correctly labeled inputs for negated and non-negated cases\n",
    "correct_negated = matrix[1, 0] + matrix[3, 1]  # Negated, correct: True Negative + True Positive\n",
    "correct_non_negated = matrix[0, 0] + matrix[2, 1]  # Non-Negated, correct: True Negative + True Positive\n",
    "\n",
    "# total negated and non-negated inputs\n",
    "total_negated = matrix[1, 0] + matrix[1, 1] + matrix[3, 0] + matrix[3, 1]\n",
    "total_non_negated = matrix[0, 0] + matrix[0, 1] + matrix[2, 0] + matrix[2, 1]\n",
    "\n",
    "# ccalculate overall percentages\n",
    "percent_correct_negated = (correct_negated / total_negated) * 100 if total_negated > 0 else 0\n",
    "percent_correct_non_negated = (correct_non_negated / total_non_negated) * 100 if total_non_negated > 0 else 0\n",
    "\n",
    "# calculate total number of correct predictions\n",
    "correct_predictions = matrix[0, 0] + matrix[1, 0] + matrix[2, 1] + matrix[3, 1]\n",
    "# print(f\" {matrix[0, 0]} \")\n",
    "# print(f\" {matrix[1, 0]} \")\n",
    "# print(f\" {matrix[2, 1]} \")\n",
    "# print(f\" {matrix[3, 1]} \")\n",
    "\n",
    "# cclculate overall accuracy\n",
    "overall_accuracy = (correct_predictions / total_test_samples) * 100\n",
    "\n",
    "# visualize the matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "im = ax.imshow(matrix, cmap=\"Blues\", aspect=\"auto\")\n",
    "\n",
    "# annotate the matrix with counts and percentages\n",
    "for i in range(matrix.shape[0]):\n",
    "    for j in range(matrix.shape[1]):\n",
    "        count = matrix[i, j]\n",
    "        percent = percent_matrix[i, j]\n",
    "        ax.text(j, i, f\"{count}\\n({percent:.2f}%)\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# add labels and titles\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks(range(4))\n",
    "ax.set_xticklabels([\"Predicted Negative\", \"Predicted Positive\"])\n",
    "ax.set_yticklabels(categories)\n",
    "ax.set_title(\"Performance Visualization Matrix (Counts and Percentages)\")\n",
    "ax.set_xlabel(\"Predicted Sentiment\")\n",
    "ax.set_ylabel(\"Input Categories\")\n",
    "\n",
    "# add overall percentages below the matrix\n",
    "fig.text(\n",
    "    0.55,\n",
    "    -0.08,\n",
    "    f\"Correctly Labeled Negated Inputs: {percent_correct_negated:.2f}%\\n\"\n",
    "    f\"Correctly Labeled Non-Negated Inputs: {percent_correct_non_negated:.2f}%\\n\"\n",
    "    f\"Overall Accuracy: {overall_accuracy:.2f}%\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    color=\"black\",\n",
    ")\n",
    "\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed0c9d-83ef-4432-83d6-8c0be3ee9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"I am not happy.\",\n",
    "    \"I don't like this product.\",\n",
    "    \"neg_not neg_happy with the service.\"\n",
    "]\n",
    "\n",
    "# tokenize the sentences\n",
    "for sentence in examples:\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    token_ids = tokenizer.encode(sentence, add_special_tokens=True)  # Includes [CLS] and [SEP] tokens\n",
    "    decoded_tokens = [tokenizer.decode([id]) for id in token_ids]\n",
    "\n",
    "    print(f\"Original Sentence: {sentence}\")\n",
    "    print(f\"Tokenized: {tokens}\")\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "    print(f\"Decoded Tokens: {decoded_tokens}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0200fa-f1e7-42f5-b29d-0c5537fced85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
